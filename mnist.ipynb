{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM1nXn1cvVERxTs95w7ySHn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/valentin-popov/mnist_pytorch_tensorflow/blob/main/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**This notebook shows two examples of neural networks based on Pytorch and Keras. The dataset used is MNIST.**"
      ],
      "metadata": {
        "id": "wjr5xNRr7kQv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Simple Neural Network using Pytorch.**\n",
        "A simple fully connected feedforward MLP-like network with an input layer (size = 28*28 = 784), an output layer (size = 10 classes) and a hidden layer. Choosing the number of neurons on the hidden layer is a matter of choice between good accuracy and low complexity."
      ],
      "metadata": {
        "id": "_ByD40Ft3C5Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "r7oxrIrC3A5h"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "mnist = fetch_openml('mnist_784')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# print(max(mnist.data[19])) # float64 [0.0 - 255.0] pixel values\n",
        "# print(type(int(mnist.target[19]))) #str -> int - labels\n",
        "\n",
        "data = np.array(mnist.data)\n",
        "target = np.array(mnist.target).astype('int32')\n",
        "# Scaling pixels values to [0, 1]\n",
        "x = (data / 255).astype('float32')\n",
        "\n",
        "# Converting the labels [0, 1, ..., 9] from str to int\n",
        "y = target.astype(int)\n",
        "\n",
        "#Splitting into train and test\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n"
      ],
      "metadata": {
        "id": "xZXrjdkGFB8C"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from skorch import NeuralNetClassifier\n",
        "\n",
        "#MLP layers dimensions\n",
        "input_dim = x.shape[1]\n",
        "hidden_dim = 50 #change the hidden_dim and notice the accuracy change\n",
        "output_dim = len(np.unique(y))\n",
        "\n",
        "\n",
        "class Network1(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim = input_dim,\n",
        "                 hidden_dim = hidden_dim,\n",
        "                 output_dim = output_dim):\n",
        "      \n",
        "        super(Network1, self).__init__()\n",
        "\n",
        "        self.hidden = nn.Linear(input_dim, hidden_dim)\n",
        "        self.output = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "\n",
        "    def forward(self, res):\n",
        "        res = torch.tanh(self.hidden(res))\n",
        "        res = F.softmax(self.output(res), dim = 0)\n",
        "        return res\n",
        "  \n",
        "\n",
        "net = NeuralNetClassifier(Network1, max_epochs = 30, lr = 0.1,)"
      ],
      "metadata": {
        "id": "y2dYO78oPaAq"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.fit(x_train, y_train);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hj5GVKmUal8",
        "outputId": "d045761a-8618-4380-8716-61da89a39638"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss    valid_acc    valid_loss     dur\n",
            "-------  ------------  -----------  ------------  ------\n",
            "      1        \u001b[36m3.3967\u001b[0m       \u001b[32m0.8926\u001b[0m        \u001b[35m3.1541\u001b[0m  1.1068\n",
            "      2        \u001b[36m3.0847\u001b[0m       \u001b[32m0.9065\u001b[0m        \u001b[35m3.0499\u001b[0m  1.1109\n",
            "      3        \u001b[36m3.0042\u001b[0m       \u001b[32m0.9164\u001b[0m        \u001b[35m2.9919\u001b[0m  1.0843\n",
            "      4        \u001b[36m2.9560\u001b[0m       \u001b[32m0.9240\u001b[0m        \u001b[35m2.9550\u001b[0m  1.1517\n",
            "      5        \u001b[36m2.9233\u001b[0m       \u001b[32m0.9284\u001b[0m        \u001b[35m2.9294\u001b[0m  1.1256\n",
            "      6        \u001b[36m2.8994\u001b[0m       \u001b[32m0.9318\u001b[0m        \u001b[35m2.9106\u001b[0m  1.0757\n",
            "      7        \u001b[36m2.8808\u001b[0m       \u001b[32m0.9340\u001b[0m        \u001b[35m2.8961\u001b[0m  1.0516\n",
            "      8        \u001b[36m2.8659\u001b[0m       \u001b[32m0.9361\u001b[0m        \u001b[35m2.8844\u001b[0m  1.0765\n",
            "      9        \u001b[36m2.8535\u001b[0m       \u001b[32m0.9378\u001b[0m        \u001b[35m2.8748\u001b[0m  1.0711\n",
            "     10        \u001b[36m2.8431\u001b[0m       \u001b[32m0.9398\u001b[0m        \u001b[35m2.8667\u001b[0m  1.0524\n",
            "     11        \u001b[36m2.8341\u001b[0m       \u001b[32m0.9409\u001b[0m        \u001b[35m2.8596\u001b[0m  1.0674\n",
            "     12        \u001b[36m2.8262\u001b[0m       \u001b[32m0.9419\u001b[0m        \u001b[35m2.8534\u001b[0m  1.0483\n",
            "     13        \u001b[36m2.8192\u001b[0m       \u001b[32m0.9426\u001b[0m        \u001b[35m2.8479\u001b[0m  1.0627\n",
            "     14        \u001b[36m2.8129\u001b[0m       \u001b[32m0.9429\u001b[0m        \u001b[35m2.8430\u001b[0m  1.1272\n",
            "     15        \u001b[36m2.8072\u001b[0m       \u001b[32m0.9434\u001b[0m        \u001b[35m2.8385\u001b[0m  1.1023\n",
            "     16        \u001b[36m2.8021\u001b[0m       \u001b[32m0.9440\u001b[0m        \u001b[35m2.8345\u001b[0m  1.0608\n",
            "     17        \u001b[36m2.7973\u001b[0m       \u001b[32m0.9448\u001b[0m        \u001b[35m2.8308\u001b[0m  1.1374\n",
            "     18        \u001b[36m2.7929\u001b[0m       \u001b[32m0.9455\u001b[0m        \u001b[35m2.8274\u001b[0m  1.1053\n",
            "     19        \u001b[36m2.7889\u001b[0m       \u001b[32m0.9463\u001b[0m        \u001b[35m2.8243\u001b[0m  1.0803\n",
            "     20        \u001b[36m2.7851\u001b[0m       \u001b[32m0.9468\u001b[0m        \u001b[35m2.8214\u001b[0m  1.0595\n",
            "     21        \u001b[36m2.7816\u001b[0m       \u001b[32m0.9478\u001b[0m        \u001b[35m2.8188\u001b[0m  1.1479\n",
            "     22        \u001b[36m2.7783\u001b[0m       \u001b[32m0.9490\u001b[0m        \u001b[35m2.8163\u001b[0m  1.1157\n",
            "     23        \u001b[36m2.7753\u001b[0m       \u001b[32m0.9496\u001b[0m        \u001b[35m2.8141\u001b[0m  1.0961\n",
            "     24        \u001b[36m2.7724\u001b[0m       \u001b[32m0.9500\u001b[0m        \u001b[35m2.8120\u001b[0m  1.1084\n",
            "     25        \u001b[36m2.7696\u001b[0m       \u001b[32m0.9505\u001b[0m        \u001b[35m2.8100\u001b[0m  1.0672\n",
            "     26        \u001b[36m2.7671\u001b[0m       \u001b[32m0.9510\u001b[0m        \u001b[35m2.8082\u001b[0m  1.0991\n",
            "     27        \u001b[36m2.7646\u001b[0m       \u001b[32m0.9518\u001b[0m        \u001b[35m2.8065\u001b[0m  1.0849\n",
            "     28        \u001b[36m2.7623\u001b[0m       \u001b[32m0.9523\u001b[0m        \u001b[35m2.8049\u001b[0m  1.0801\n",
            "     29        \u001b[36m2.7601\u001b[0m       \u001b[32m0.9529\u001b[0m        \u001b[35m2.8034\u001b[0m  1.0668\n",
            "     30        \u001b[36m2.7580\u001b[0m       \u001b[32m0.9529\u001b[0m        \u001b[35m2.8020\u001b[0m  1.0559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = net.predict(x_test)\n",
        "print(\"Accuracy: {}%\".format(round(100 * accuracy_score(y_test, y_pred))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADlFLQL6aL8F",
        "outputId": "e64436ac-2db4-43b3-dcd3-8a6aec965ae0"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Convolutional Neural Network (CNN) using Tensorflow Keras**\n",
        "Things are a little more complex in a convolutional neural network (CNN) context, but a convolutional architecture gives a higher accuracy. For faster training enable GPU (Runtime -> Change runtime type).\n",
        "\n"
      ],
      "metadata": {
        "id": "HjaT2gVPdQLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Input, Conv2D, MaxPooling2D, Dropout, Flatten\n",
        "\n",
        "\n",
        "#Fetching the data split into train and test\n",
        "#x arrays - images, y arrays - labels(classes)\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = (x_train / 255).astype('float32')\n",
        "x_test = (x_test / 255).astype('float32')\n",
        "\n",
        "# The y arrays are turned into 2D arrays. For every row in the array\n",
        "# the index of the single non-zero element is the right class.\n",
        "y_train = tensorflow.keras.utils.to_categorical(y_train)\n",
        "y_test = tensorflow.keras.utils.to_categorical(y_test)\n",
        "\n",
        "# format = (height, width, no_channels)\n",
        "# tuple to keras tensor\n",
        "input = Input((28, 28, 1))\n",
        "layer1 = Conv2D(16, kernel_size=(3, 3), activation='relu')(input)\n",
        "layer2 = Conv2D(32, (3, 3), activation='relu')(layer1)\n",
        "layer3 = MaxPooling2D(pool_size=(3, 3))(layer2)\n",
        "layer4 = Dropout(0.5)(layer3)\n",
        "layer5 = Flatten()(layer4)\n",
        "layer6 = Dense(100, activation='sigmoid')(layer5)\n",
        "layer7 = Dense(10, activation='softmax')(layer6)\n",
        "output = layer7\n",
        "\n",
        "model = Model([input], output)\n",
        "model.compile(optimizer=tensorflow.keras.optimizers.Adam(),\n",
        "\t\t\tloss=keras.losses.categorical_crossentropy,\n",
        "\t\t\tmetrics=['accuracy'])"
      ],
      "metadata": {
        "id": "cmewJ5Bjd-ex"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs = 10, batch_size = 1000)\n",
        "\n",
        "score = model.evaluate(x_test, y_test)\n",
        "print('Loss =', score[0])\n",
        "print('Accuracy = {}%'.format(round(100*score[1])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytMuIedcdR9L",
        "outputId": "5ea8a81c-5b1f-4d01-f58f-2309a9f0517b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "60/60 [==============================] - 3s 42ms/step - loss: 0.0435 - accuracy: 0.9873\n",
            "Epoch 2/10\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.0420 - accuracy: 0.9880\n",
            "Epoch 3/10\n",
            "60/60 [==============================] - 3s 42ms/step - loss: 0.0403 - accuracy: 0.9883\n",
            "Epoch 4/10\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.0388 - accuracy: 0.9888\n",
            "Epoch 5/10\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.0368 - accuracy: 0.9895\n",
            "Epoch 6/10\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.0360 - accuracy: 0.9898\n",
            "Epoch 7/10\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.0353 - accuracy: 0.9906\n",
            "Epoch 8/10\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.0344 - accuracy: 0.9896\n",
            "Epoch 9/10\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.0332 - accuracy: 0.9905\n",
            "Epoch 10/10\n",
            "60/60 [==============================] - 2s 40ms/step - loss: 0.0317 - accuracy: 0.9911\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 0.0286 - accuracy: 0.9917\n",
            "Loss = 0.028571655973792076\n",
            "Accuracy = 99%\n"
          ]
        }
      ]
    }
  ]
}